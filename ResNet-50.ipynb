# --- 基本 import ---
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt

from keras import Input, Model, optimizers, regularizers, applications
from keras.layers import GlobalAveragePooling2D, Dropout, Dense
from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers.schedules import CosineDecay
import tensorflow as tf

# --- 參數設定 ---
BATCH_SIZE = 8
EPOCHS = 30
HEIGHT = 512
WIDTH = 512
CHANNEL = 3

WARMUP_EPOCHS = 2
LEARNING_RATE = 5e-5
WARMUP_LEARNING_RATE = 1e-4
DECAY_DROP = 0.5
ES_PATIENCE = 5
RLROP_PATIENCE = 3

# --- 資料前處理 ---
train["id_code"] = train["id_code"].apply(lambda x: x + ".png")
test["id_code"] = test["id_code"].apply(lambda x: x + ".png")
train['diagnosis'] = train['diagnosis'].astype(str)
N_CLASSES = train['diagnosis'].nunique()

# --- 資料增強 Augmentation ---
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=10,
    width_shift_range=0.05,
    height_shift_range=0.05,
    shear_range=0.0,
    zoom_range=0.05,
    horizontal_flip=True,
    brightness_range=[0.9, 1.1],
    fill_mode='nearest'
)

train_generator = train_datagen.flow_from_dataframe(
    dataframe=train,
    directory="../input/aptos2019-blindness-detection/train_images/",
    x_col="id_code",
    y_col="diagnosis",
    target_size=(HEIGHT, WIDTH),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset='training',
    shuffle=True
)

valid_generator = train_datagen.flow_from_dataframe(
    dataframe=train,
    directory="../input/aptos2019-blindness-detection/train_images/",
    x_col="id_code",
    y_col="diagnosis",
    target_size=(HEIGHT, WIDTH),
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    subset='validation',
    shuffle=False
)

# --- 建立模型 ---
def create_model(input_shape, n_out):
    input_tensor = Input(shape=input_shape)
    base_model = applications.EfficientNetB0(
        weights='imagenet',
        include_top=False,
        input_tensor=input_tensor
    )
    x = GlobalAveragePooling2D()(base_model.output)
    x = Dropout(0.5)(x)
    x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)
    x = Dropout(0.5)(x)
    final_output = Dense(n_out, activation='softmax')(x)
    model = Model(inputs=input_tensor, outputs=final_output)
    return model

model = create_model(input_shape=(HEIGHT, WIDTH, CHANNEL), n_out=N_CLASSES)

# --- Compile模型 ---
cosine_decay = CosineDecay(
    initial_learning_rate=LEARNING_RATE,
    decay_steps=len(train_generator) * EPOCHS
)
optimizer = optimizers.Adam(learning_rate=cosine_decay)

model.compile(
    optimizer=optimizer,
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

# --- Callbacks: EarlyStopping + ReduceLR + ModelCheckpoint ---
es = EarlyStopping(monitor='val_loss', patience=ES_PATIENCE, restore_best_weights=True, verbose=1)
rlrop = ReduceLROnPlateau(monitor='val_loss', factor=DECAY_DROP, patience=RLROP_PATIENCE, verbose=1)
mc = ModelCheckpoint("best_model.h5", monitor="val_loss", save_best_only=True, verbose=1)

callbacks_list = [es, rlrop, mc]

# --- 訓練模型 ---
history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=EPOCHS,
    callbacks=callbacks_list,
    verbose=1
)

# --- 畫圖：Training & Validation Loss/Accuracy 曲線 ---
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Loss Curve')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.title('Accuracy Curve')
plt.legend()

plt.show()

